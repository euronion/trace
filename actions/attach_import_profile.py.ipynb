{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake.params[\"scenario\"][\"import_buffer\"] = \"annually\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import dateutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pypsa\n",
    "from _helpers import configure_logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    scenario = snakemake.params[\"scenario\"]\n",
    "    configure_logging(snakemake)\n",
    "\n",
    "    with open(snakemake.input[\"additional_components\"], \"rb\") as f:\n",
    "        override_component_attrs = pickle.load(f)\n",
    "\n",
    "    network = pypsa.Network(override_component_attrs=override_component_attrs)\n",
    "    network.import_from_netcdf(snakemake.input[\"network\"])\n",
    "\n",
    "    # Determine all loads related to imports (on the importer side of the ESC)\n",
    "    import_loads = network.loads[network.loads.bus.str.contains(\"imp\")]\n",
    "\n",
    "    # Read load profile from file\n",
    "    df = pd.read_csv(snakemake.input[\"import_profile\"])\n",
    "\n",
    "    # File format consistency checks\n",
    "    if {\"snapshot\", \"profile [p.u.]\"} != set(\n",
    "        pd.read_csv(snakemake.input[\"import_profile\"]).columns\n",
    "    ):\n",
    "        logger.error(\n",
    "            f\"Import profile file '{snakemake.input['import_profile']}' must have \"\n",
    "            f\"exactly two columns 'snapshot' and 'profile [p.u.]'\"\n",
    "        )\n",
    "    elif np.any(pd.to_datetime(df[\"snapshot\"]) != network.snapshots):\n",
    "        logger.error(\n",
    "            f\"At least one 'snapshot' entry in '{snakemake.input['import_profile']}' \"\n",
    "            f\"does not match the network snapshots: {network.snapshots[:5], ...}.\"\n",
    "        )\n",
    "\n",
    "    df = df.set_index(\"snapshot\")\n",
    "\n",
    "    # Apply the import_profile to all importing loads in the network\n",
    "    for load, load_s in import_loads.iterrows():\n",
    "        import_profile = load_s[\"p_set\"] * df[\"profile [p.u.]\"]\n",
    "        network.loads_t[\"p_set\"][load] = import_profile\n",
    "        network.loads.loc[load, \"p_set\"] = 0\n",
    "\n",
    "    # Add optional buffers to the import loads\n",
    "    if scenario[\"import_buffer\"] is False:\n",
    "        logger.info(\"Imports are not buffered.\")\n",
    "    elif scenario[\"import_buffer\"] == \"annually\":\n",
    "        logger.info(\"Imports are buffered on an annual basis, adding buffer stores.\")\n",
    "\n",
    "        # Implement annual import_buffer by adding a store\n",
    "        # to the bus of each load on the import side\n",
    "        network.madd(\n",
    "            \"Store\",\n",
    "            names=\"Buffer: \" + import_loads.index,\n",
    "            bus=import_loads.bus.values,\n",
    "            e_nom_extendable=True,\n",
    "            e_cyclic=True,\n",
    "        )\n",
    "\n",
    "    # For informative purposes in any configuration case\n",
    "    logger.info(f\"\\t import_buffer:{scenario['import_buffer']}.\")\n",
    "\n",
    "    network.export_to_netcdf(snakemake.output[\"network\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
