{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pypsa\n",
    "from _helpers import configure_logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from pypsa.linopt import define_constraints, get_var, linexpr\n",
    "\n",
    "\n",
    "def extra_functionality(n, snapshots):\n",
    "    \"\"\"... for solving the network; from pypsa-eur-sec.\"\"\"\n",
    "    add_battery_constraints(n)\n",
    "\n",
    "    if n.name == \"LOHC shipping\":\n",
    "        add_LOHC_shipping_constraints(n)\n",
    "        add_LOHC_chemical_constraint(n)\n",
    "\n",
    "\n",
    "def add_battery_constraints(n):\n",
    "    \"\"\"Constraint for battery inverter capacity.\n",
    "\n",
    "    Assumed battery inverter is bidirectional.\n",
    "    Enforce same capacity for charging/discharging link.\n",
    "\n",
    "    From pypsa-eur-sec. (2020-12-14)\n",
    "    \"\"\"\n",
    "\n",
    "    chargers = n.links.query(\n",
    "        \"index.str.startswith('battery inverter') \"\n",
    "        \"and bus1.str.startswith('battery') \"\n",
    "        \"and p_nom_extendable\",\n",
    "        engine=\"python\",\n",
    "    ).index\n",
    "    dischargers = n.links.query(\n",
    "        \"index.str.startswith('battery inverter') \"\n",
    "        \"and bus0.str.startswith('battery') \"\n",
    "        \"and p_nom_extendable\",\n",
    "        engine=\"python\",\n",
    "    ).index\n",
    "\n",
    "    link_p_nom = get_var(n, \"Link\", \"p_nom\")\n",
    "    lhs = linexpr((1, link_p_nom[chargers]), (-1, link_p_nom[dischargers].values))\n",
    "    pypsa.linopt.define_constraints(n, lhs, \"=\", 0, \"Link\", \"charger_ratio\")\n",
    "\n",
    "\n",
    "def add_LOHC_shipping_constraints(n):\n",
    "    \"\"\"Constraint for shipping of LOHC to ensure consistent cargo capacity.\n",
    "\n",
    "    LOHC requires an additional cargo store per convoy to store used LOHC produced\n",
    "    during the journey or transported from the importer back to the exporter during\n",
    "    the inbound journey.\n",
    "    This constraint ensures that this LOHC (used) store is of the same size as the cargo\n",
    "    store, i.e. the ships size is determined by the cargo store and the LOHC (used) store\n",
    "    may not exceed this capacity.\n",
    "    \"\"\"\n",
    "\n",
    "    lohc_stores = n.stores.filter(like=\"cargo LOHC (used)\", axis=0).index\n",
    "    cargo_stores = lohc_stores.str.replace(\"cargo LOHC \\(used\\)\", \"cargo (exp)\")\n",
    "\n",
    "    stores_e_nom = get_var(n, \"Store\", \"e_nom\")\n",
    "\n",
    "    lhs = linexpr(\n",
    "        (1, stores_e_nom[cargo_stores]), (-1.0, stores_e_nom[lohc_stores].values)\n",
    "    )\n",
    "\n",
    "    pypsa.linopt.define_constraints(n, lhs, \"=\", 0, \"Store\", \"lohc_shipping_constraint\")\n",
    "\n",
    "\n",
    "def add_LOHC_chemical_constraint(n):\n",
    "\n",
    "    # for DBT: 0.944t LOHC per 1 t of loaded LOHC\n",
    "    lohc_dbt_share = n.links.loc[\"LOHC dehydrogenation (imp)\", \"efficiency2\"]\n",
    "\n",
    "    loaded_stores = n.stores.filter(like=\"LOHC unloaded\", axis=0).index.union(\n",
    "        n.stores.filter(\n",
    "            regex=\"LOHC transport ship convoy \\d+ cargo \\(exp\\)\", axis=0\n",
    "        ).index\n",
    "    )\n",
    "\n",
    "    unloaded_stores = n.stores.filter(like=\"LOHC loaded\", axis=0).index.union(\n",
    "        n.stores.filter(\n",
    "            regex=\"LOHC transport ship convoy \\d+ cargo LOHC \\(used\\)\", axis=0\n",
    "        ).index\n",
    "    )\n",
    "\n",
    "    generator_p_nom = get_var(n, \"Generator\", \"p_nom\")\n",
    "    stores_e = get_var(n, \"Store\", \"e\")\n",
    "\n",
    "    lhs = linexpr(\n",
    "        (1, stores_e[unloaded_stores]), (lohc_dbt_share, stores_e[loaded_stores].values)\n",
    "    ).sum(1)\n",
    "    lhs += linexpr((-1, generator_p_nom[\"LOHC chemical (exp)\"]))[0]\n",
    "\n",
    "    pypsa.linopt.define_constraints(\n",
    "        n, lhs, \"<=\", 0, \"Generator\", f\"lohc_chemical__constraint\"\n",
    "    )\n",
    "\n",
    "\n",
    "def clean_network(n):\n",
    "    \"\"\"\n",
    "    Some additional housekeeping before the optimisation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set cost for all components with 0 capital cost/capital_cost to defaults from config\n",
    "    # to avoid solver shenannigans due to 0 +/- eps\n",
    "    for components_name in [\"links\", \"stores\", \"generators\"]:\n",
    "\n",
    "        for p in [\"capital_cost\", \"marginal_cost\"]:\n",
    "\n",
    "            components = getattr(n, components_name)\n",
    "            idx = components.query(f\"{p} == 0\").index\n",
    "            components.loc[idx, p] = scenario[p][\"default\"]\n",
    "\n",
    "    n.consistency_check()\n",
    "\n",
    "    return n\n",
    "\n",
    "\n",
    "def apply_modifiers(n):\n",
    "    \"Apply modifiers from config.yaml .\"\n",
    "\n",
    "    # Apply modifier to CAPEX\n",
    "    mapping = [\n",
    "        (\"links\", \"electrolysis\", \"CAPEX_electrolysis\"),\n",
    "        (\"links\", \"battery inverter\", \"CAPEX_battery\"),\n",
    "        (\"stores\", \"battery\", \"CAPEX_battery\"),\n",
    "        (\"generators\", \"pvplant|wind\", \"CAPEX_RES\"),\n",
    "        (\"links\", \"pipeline\", \"CAPEX_pipeline\"),\n",
    "        (\"links\", \"methanolisation\", \"CAPEX_MeOHSynthesis\"),\n",
    "    ]\n",
    "    for (components_name, search_string, modifier_name) in mapping:\n",
    "        c = getattr(n, components_name)\n",
    "        c.loc[c.index.str.contains(search_string), \"capital_cost\"] *= scenario[\n",
    "            \"modifiers\"\n",
    "        ][modifier_name]\n",
    "\n",
    "    # Apply modifier to loads (static and time-dependent equally)\n",
    "    n.loads[\"p_set\"] *= scenario[\"modifiers\"][\"import_demand\"]\n",
    "    n.loads_t[\"p_set\"] *= scenario[\"modifiers\"][\"import_demand\"]\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb285426",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    configure_logging(snakemake)\n",
    "    scenario = snakemake.params[\"scenario\"]\n",
    "\n",
    "    for op in snakemake.config[\"solver\"].keys():\n",
    "        solver_options = snakemake.config[\"solver\"][op].copy()\n",
    "        solver_name = solver_options.pop(\"name\")\n",
    "\n",
    "        # Load additional components\n",
    "        with open(snakemake.input[\"additional_components\"], \"rb\") as f:\n",
    "            override_component_attrs = pickle.load(f)\n",
    "        network = pypsa.Network(override_component_attrs=override_component_attrs)\n",
    "        \n",
    "        network.import_from_netcdf(snakemake.input[\"network\"])\n",
    "        network = apply_modifiers(network)\n",
    "        network = clean_network(network)\n",
    "\n",
    "        logger.info(\n",
    "            f'Solving network using solver options \"{op}\":\\n' f\"{solver_options}\"\n",
    "        )\n",
    "        logger.info(\"Starting LOPF.\")\n",
    "        status, termination_condition = network.lopf(\n",
    "            snapshots=network.snapshots,\n",
    "            extra_functionality=extra_functionality,\n",
    "            pyomo=False,\n",
    "            solver_name=solver_name,\n",
    "            solver_options=solver_options,\n",
    "            solver_logfile=snakemake.log[\"python\"],\n",
    "        )\n",
    "        logger.info(\"End of LOPF.\")\n",
    "\n",
    "        if status == \"ok\":\n",
    "            network.export_to_netcdf(snakemake.output[\"network\"])\n",
    "            break\n",
    "        elif status == \"warning\" and termination_condition == \"suboptimal\":\n",
    "            logger.info(\n",
    "                \"Suboptimal optimisation result. \"\n",
    "                'Saving as \"_suboptimal.nc in case you want to use it.'\n",
    "            )\n",
    "            network.export_to_netcdf(\n",
    "                snakemake.output[\"network\"].replace(\".nc\", \"_suboptimal.nc\")\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\n",
    "                f\"Optimsation ended with \\n\"\n",
    "                f\"\\tstatus: {status}\\n\"\n",
    "                f\"\\ttermination condition: {termination_condition}\\n\"\n",
    "                f\"Unoptimised network not saved.\"\n",
    "                f\"Retrying with different solver config.\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
