{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a38487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "import atlite\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import shapely.validation as shpval\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from _helpers import configure_logging\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    configure_logging(snakemake)\n",
    "\n",
    "    # Split for each region member the different levels of GADM and remove whitespaces\n",
    "    region_members = [re.split(\"\\s*->\\s*\", m) for m in snakemake.params.region_members]\n",
    "\n",
    "    # Sort based on length; Lists with less elements are for a higher GADM level and are consumed first\n",
    "    region_members = sorted(region_members, key=len)\n",
    "\n",
    "    # Read at maximum until level4\n",
    "    layers_to_read = [f\"level{i}\" for i in range(5)]\n",
    "\n",
    "    # Construct dict indicating in which GADM level to search for each region_member\n",
    "    # and the respective field names to compare against\n",
    "    search_targets = {layer: [] for layer in layers_to_read}\n",
    "    for member in region_members:\n",
    "        member_entry = {\n",
    "            f\"NAME_{position}\": element for position, element in enumerate(member)\n",
    "        }\n",
    "        search_layer = f\"level{len(member)-1}\"\n",
    "        search_targets[search_layer].append(member_entry)\n",
    "\n",
    "    # Holds all found geometries for region members from different layers\n",
    "    member_geometries = []\n",
    "\n",
    "    # Load GADM and search for all region members in the correct layers\n",
    "    for search_layer, search_target in search_targets.items():\n",
    "        # Only search layer if we expect a region_member to be in this layer\n",
    "        if search_target:\n",
    "            gadm = gpd.read_file(snakemake.input[\"gadm\"], layer=search_layer)\n",
    "\n",
    "            # Collapse dict into dict of lists for easier use with pandas\n",
    "            search_target = pd.DataFrame(search_target).to_dict(\"list\")\n",
    "\n",
    "            # Select all entries with matching columns/values\n",
    "            gadm = gadm.loc[\n",
    "                gadm[search_target.keys()].isin(search_target).all(axis=\"columns\")\n",
    "            ]\n",
    "\n",
    "            member_geometries.append(gadm)\n",
    "\n",
    "    if len(member_geometries) == 0:\n",
    "        logger.error(\n",
    "            f\"No matching entries on GADM found for region '{snakemake.wildcards['region']}'. \"\n",
    "            f\"Requested region members: {region_members}.\"\n",
    "            f\"Check correct and matching spelling with https://gadm.org .\"\n",
    "        )\n",
    "\n",
    "    member_geometries = pd.concat(member_geometries)\n",
    "\n",
    "    member_geometries[\"country\"] = member_geometries[\"NAME_0\"]\n",
    "\n",
    "    # Read EEZs for potential offshore locations and\n",
    "    # add EEZs for all involved countries\n",
    "    # (neglecting proximity to specified members for now)\n",
    "    eez = gpd.read_file(snakemake.input[\"eez\"])\n",
    "\n",
    "    # Drop entries without ISO_TER1 entry\n",
    "    # These are mostly small island states + Hawaii\n",
    "    eez = eez.dropna(axis=0, how=\"any\", subset=[\"ISO_TER1\"])\n",
    "\n",
    "    # Determine associated country names for EEZs\n",
    "    eez[\"country\"] = eez[\"ISO_TER1\"].map(\n",
    "        lambda c: pycountry.countries.get(alpha_3=c).name\n",
    "    )\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    eez = eez[[\"country\", \"geometry\"]]\n",
    "\n",
    "    # Relevant countries\n",
    "    eez = eez[eez[\"country\"].isin(member_geometries[\"NAME_0\"].unique())]\n",
    "\n",
    "    # .buffer(...) operation used later is significantly faster and more efficient\n",
    "    # on exploded shape compared to MultiPolygon.\n",
    "    # -> explode -> buffer -> union\n",
    "    member_geometries = member_geometries.explode(ignore_index=True)\n",
    "\n",
    "    ## Switch to CRS with m[etres] as unit\n",
    "\n",
    "    # Use Mollweide CRS for estimating offshore distance and adjacency in m[etre]\n",
    "    # Mollweide is not very accurate at high latitudes, but sufficient for\n",
    "    # this initial step and large offshore_proximity values.\n",
    "    # See: https://epsg.io/54009\n",
    "    # and Usery and Seong (2001), doi:10.1559/152304001782153053\n",
    "    crs_m = \"ESRI:54009\"\n",
    "    crs_org = gadm.crs\n",
    "\n",
    "    member_geometries = member_geometries.to_crs(crs_m)\n",
    "    eez = eez.to_crs(crs_m)\n",
    "\n",
    "    # For determining offshore regions we only need to buffer the boundary\n",
    "    # of the onshore region + simplification doesn't hurt/might improve niceiness of shapes\n",
    "    mgb = member_geometries.copy(deep=True)\n",
    "    mgb[\"geometry\"] = mgb.boundary\n",
    "    mgb[\"geometry\"] = mgb.simplify(100)\n",
    "\n",
    "    # First only consider offshore regions which are adjacent to any onshore region\n",
    "    # Use buffer to prevent small gaps to overeagerly exclude an offshore region\n",
    "    eez = eez[eez.geometry.intersects(mgb.buffer(100).unary_union)]\n",
    "\n",
    "    logger.info(\n",
    "        f\"{len(eez)} offshore region(s) found for region '{snakemake.wildcards.region}'.\"\n",
    "    )\n",
    "    if len(eez) > 0:\n",
    "        ## Select only offshore locations within <offshore_proximity> m[eters] of\n",
    "        ## an onshore location which is part of the region\n",
    "        ## (=offshore locations accessible from the region under consideration)\n",
    "        # offshore = eez.intersection(mgb.buffer(snakemake.params.offshore_proximity).unary_union)\n",
    "\n",
    "        # Combine offshore region into MultiPolygon\n",
    "        offshore = eez.unary_union\n",
    "        offshore = offshore.simplify(0)\n",
    "        offshore = shpval.make_valid(offshore)\n",
    "\n",
    "    else:\n",
    "        offshore = None\n",
    "\n",
    "    # Merge onshore regions into one\n",
    "    onshore = member_geometries.unary_union\n",
    "    onshore = onshore.simplify(0)\n",
    "    onshore = shpval.make_valid(onshore)\n",
    "\n",
    "    ## Combine resulting region masks and convert back to original CRS for saving\n",
    "    region_masks = gpd.GeoDataFrame(\n",
    "        gpd.GeoSeries(\n",
    "            [onshore, offshore],\n",
    "            index=[\"onshore\", \"offshore\"],\n",
    "            name=\"geometry\",\n",
    "            crs=crs_m,\n",
    "        )\n",
    "    )\n",
    "    region_masks = region_masks.to_crs(crs_org)\n",
    "\n",
    "    # Save all region geometries into single file\n",
    "    region_masks.to_file(snakemake.output[\"gpkg\"], driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
